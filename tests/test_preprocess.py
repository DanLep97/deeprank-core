from tempfile import mkdtemp
from shutil import rmtree
from os.path import join
import h5py
from deeprankcore.preprocess import preprocess
from typing import List, Union
from types import ModuleType
from deeprankcore.features import surfacearea
from deeprankcore.query import SingleResidueVariantResidueQuery
from deeprankcore.domain.aminoacidlist import alanine, phenylalanine
from tests._utils import PATH_TEST
from os.path import join


def preprocess_tester(count: int, combine_files: bool, feature_modules: Union[List[ModuleType], str]):
    """
    Generic function to test preprocessing several PDB files into their feature representation HDF5 file.

    Args:
        feature_modules: list of feature modules (from .deeprankcore.features) to be passed to preprocess.
            If "all", all available modules in deeprankcore.features are used to generate the features.

        count: number of queries to be generated and number of cpus to be used during the preprocessing.

        combine_files: boolean for combining the hdf5 files generated by the subprocesses.
            By default, the hdf5 files generated are combined into one, and then deleted.
    """

    output_directory = mkdtemp()
    prefix = join(output_directory, "test-preprocess")

    try:
        queries = []
        for number in range(1, count + 1):
            query = SingleResidueVariantResidueQuery(
                str(PATH_TEST / "data/pdb/101M/101M.pdb"),
                "A",
                number,
                None,
                alanine,
                phenylalanine,
                pssm_paths={"A": str(PATH_TEST / "data/pssm/101M/101M.A.pdb.pssm")},
            )
            queries.append(query)

        output_paths = preprocess(queries, prefix, count, combine_files, feature_modules)
        assert len(output_paths) > 0

        graph_names = []
        for path in output_paths:
            with h5py.File(path, "r") as f5:
                graph_names += list(f5.keys())

        for query in queries:
            query_id = query.get_query_id()
            assert query_id in graph_names, f"missing in output: {query_id}"
    except Exception as e:
        print(e)

    return output_directory, output_paths


def test_preprocess_single_feature():
    """
    Tests preprocessing for generating a single feature.
    """
    output_directory, _ = preprocess_tester(5, False, [surfacearea])

    rmtree(output_directory)


def test_preprocess_all_features():
    """
    Tests preprocessing for generating all features.
    """

    output_directory, _ = preprocess_tester(5, False, "all")

    rmtree(output_directory)


def test_preprocess_combine_files_true():
    """
    Tests preprocessing for combining hdf5 files into one.
    """

    output_directory, output_paths = preprocess_tester(5, True, "all")
    
    assert len(output_paths) == 1

    rmtree(output_directory)


def test_preprocess_combine_files_false():
    """
    Tests preprocessing for keeping hdf5 files .
    """

    output_directory, output_paths = preprocess_tester(5, False, "all")
    
    assert len(output_paths) == 5

    rmtree(output_directory)
